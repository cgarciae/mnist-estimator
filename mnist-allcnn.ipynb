{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataget import data\n",
    "import tfinterface as ti\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cytoolz as cz\n",
    "from dicto import dicto\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataget\n",
    "To download and import the data we will use dataget here but you can import the mnist however you want, there are various ways to import the mnist like using keras sample datasets. The first time you run this code `dataget` will download, extract, and transform the `MNIST` to jpg images; any subsequent calls use the cached data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'class_id', u'filename'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data(\"mnist\").get()\n",
    "\n",
    "dataset.training_set.df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.get` method returns a `Dataset` object which has a `training_set` and `test_set` `SubSet` properties, these subsets include varios methods for loading the images, getting random batches, etc. However, each subset by default include a `.df` property which the columns filename (full path to the actual image) and class_id (number show in the image), although you sometimes wan't a generator of (image, label) batches, we will make TensorFlow do the IO for us so just having the filenames is perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator API, input_fn & Dataset API\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(df, img_shape = [28, 28], embeddings_shape = [1, 1, 100], epochs = 10, batch_size = 64, buffer_size = 500):\n",
    "\n",
    "    def parse(filename, class_id):\n",
    "\n",
    "        img = tf.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img, channels = 1)\n",
    "        img = tf.image.resize_images(img, img_shape)\n",
    "\n",
    "        return img, class_id\n",
    "\n",
    "\n",
    "    # ds\n",
    "    ds = tf.data.Dataset.from_tensor_slices((df.filename.as_matrix(), df.class_id.as_matrix()))\n",
    "    ds = ds.map(parse)\n",
    "    ds = ds.shuffle(buffer_size = buffer_size)\n",
    "    ds = ds.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n",
    "    ds = ds.repeat(epochs)\n",
    "\n",
    "    # get iterator\n",
    "    iterator = ds.make_one_shot_iterator()\n",
    "    image, class_id = iterator.get_next()\n",
    "\n",
    "    return dict(image = image, class_id = class_id), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_id': <tf.Tensor 'IteratorGetNext:1' shape=(20,) dtype=int64>, 'image': <tf.Tensor 'IteratorGetNext:0' shape=(20, 28, 28, 1) dtype=float32>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristian/anaconda2/lib/python2.7/site-packages/matplotlib/figure.py:403: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABbCAYAAABEQP/sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2XEcJxH+H9mAKsRV5N+XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9180965890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABbCAYAAABEQP/sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f917b7ded90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABbCAYAAABEQP/sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGIlgA7JhGEYi2IBsGIaRCP8PWuwNqQeqGx8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f917b79c8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABbCAYAAABEQP/sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f917b6b5cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features, _ = input_fn(dataset.training_set.df, batch_size=20)\n",
    "\n",
    "image = features[\"image\"]\n",
    "class_id = features[\"class_id\"]\n",
    "\n",
    "print(features)\n",
    "    \n",
    "images, class_ids = sess.run([image, class_id])\n",
    "\n",
    "for tup in cz.partition(5, zip(images, class_ids)):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, subplot_kw=dict())\n",
    "\n",
    "    for i, (img, class_id) in enumerate(tup):\n",
    "\n",
    "\n",
    "        img = np.squeeze(img).astype(np.uint8)\n",
    "\n",
    "        axes[i].imshow(img, cmap=\"gray\")\n",
    "        axes[i].title.set_text(class_id)\n",
    "        axes[i].get_yaxis().set_visible(False)\n",
    "        axes[i].get_xaxis().set_visible(False)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllCNNN(snt.AbstractModule):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs[\"name\"] = kwargs.get(\"name\", \"AllCNN\")\n",
    "        super(AllCNNN, self).__init__(*args, **kwargs)\n",
    "    \n",
    "    def _build(self, inputs):\n",
    "        \n",
    "        print(\"##########################\")\n",
    "        print(\"## AllCNN\")\n",
    "        print(\"##########################\")\n",
    "        \n",
    "        net = inputs[\"image\"]; print(net)\n",
    "        training = inputs[\"mode\"] == tf.estimator.ModeKeys.TRAIN\n",
    "        \n",
    "        net = ti.layers.conv2d_batch_norm(net, 16, [4, 4], strides = 2, activation = tf.nn.relu, \n",
    "                                          padding = \"same\", batch_norm = dict(training = training)); print(net)\n",
    "        \n",
    "        \n",
    "        net = ti.layers.conv2d_batch_norm(net, 32, [4, 4], strides = 2, activation = tf.nn.relu, \n",
    "                                          padding = \"same\", batch_norm = dict(training = training)); print(net)\n",
    "        \n",
    "        \n",
    "        net = ti.layers.conv2d_batch_norm(net, 64, [3, 3], strides = 1, activation = tf.nn.relu, \n",
    "                                          padding = \"valid\", batch_norm = dict(training = training)); print(net)\n",
    "        \n",
    "        \n",
    "        net = tf.layers.conv2d(net, 10, [3, 3], strides = 1, activation = tf.nn.relu,\n",
    "                                          padding = \"valid\"); print(net)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # global average pooling\n",
    "        logits = net = tf.reduce_mean(net, axis = [1, 2]); print(net)\n",
    "        \n",
    "        # predictions\n",
    "        predictions = net = tf.nn.softmax(logits); print(net)\n",
    "    \n",
    "        print(\"\")\n",
    "        \n",
    "        return logits, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "## AllCNN\n",
      "##########################\n",
      "Tensor(\"input_layer_1:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm/Relu:0\", shape=(?, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm_1/Relu:0\", shape=(?, 7, 7, 32), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm_2/Relu:0\", shape=(?, 5, 5, 64), dtype=float32)\n",
      "Tensor(\"AllCNN/conv2d/Relu:0\", shape=(?, 3, 3, 10), dtype=float32)\n",
      "Tensor(\"AllCNN/Mean:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"AllCNN/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = dict(\n",
    "    image = tf.layers.Input(shape=(28, 28, 1)),\n",
    "    mode = tf.estimator.ModeKeys.TRAIN,\n",
    ")\n",
    "\n",
    "all_cnn = AllCNNN()\n",
    "logits, predictions = all_cnn(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \n",
    "    inputs = features\n",
    "    inputs[\"mode\"] = mode\n",
    "    \n",
    "    # create networks\n",
    "    all_cnn = AllCNNN()\n",
    "    \n",
    "    # predictions\n",
    "    logits, predictions = all_cnn(inputs)\n",
    "    \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode = mode,\n",
    "            predictions = dict(\n",
    "                classes = predictions,\n",
    "                image = inputs[\"image\"],\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # loss\n",
    "    labels = features[\"class_id\"]\n",
    "    onehot_labels = tf.one_hot(labels, 10)\n",
    "    \n",
    "    loss = tf.losses.softmax_cross_entropy(logits = logits, onehot_labels = onehot_labels)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode = mode,\n",
    "            predictions = predictions,\n",
    "            loss = loss,\n",
    "            eval_metric_ops = dict(\n",
    "                accuracy = tf.metrics.accuracy(\n",
    "                    labels = labels,\n",
    "                    predictions = tf.argmax(predictions, axis = 1)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    #update\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        update = tf.train.AdamOptimizer(params[\"learning_rate\"]).minimize(loss, global_step = tf.train.get_global_step())\n",
    "        \n",
    "    \n",
    "    accuracy = tf.contrib.metrics.accuracy(\n",
    "        labels = labels,\n",
    "        predictions = tf.argmax(predictions, axis = 1)\n",
    "    )\n",
    "        \n",
    "    # metrics\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    \n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = predictions,\n",
    "        loss = loss,\n",
    "        train_op = update,\n",
    "        training_hooks = [\n",
    "            tf.train.LoggingTensorHook(\n",
    "                dict(\n",
    "                    loss = loss, \n",
    "                    accuracy = accuracy\n",
    "                ),  \n",
    "                every_n_iter = 50\n",
    "            )\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f91ec53cc10>, '_save_checkpoints_steps': 50, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'models/all_cnn2', '_save_summary_steps': 50}\n"
     ]
    }
   ],
   "source": [
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn = model_fn,\n",
    "    model_dir = params.model_dir,\n",
    "    params = params,\n",
    "    config = tf.estimator.RunConfig(save_checkpoints_steps = params.checkpoint_steps, save_summary_steps = params.summary_steps)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "## AllCNN\n",
      "##########################\n",
      "Tensor(\"IteratorGetNext:0\", shape=(64, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm/Relu:0\", shape=(64, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm_1/Relu:0\", shape=(64, 7, 7, 32), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm_2/Relu:0\", shape=(64, 5, 5, 64), dtype=float32)\n",
      "Tensor(\"AllCNN/conv2d/Relu:0\", shape=(64, 3, 3, 10), dtype=float32)\n",
      "Tensor(\"AllCNN/Mean:0\", shape=(64, 10), dtype=float32)\n",
      "Tensor(\"AllCNN/Softmax:0\", shape=(64, 10), dtype=float32)\n",
      "\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from models/all_cnn2/model.ckpt-302\n",
      "INFO:tensorflow:Saving checkpoints for 303 into models/all_cnn2/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.149795, step = 303\n",
      "INFO:tensorflow:loss = 0.149795, accuracy = 0.96875\n",
      "INFO:tensorflow:Saving checkpoints for 353 into models/all_cnn2/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0390556, accuracy = 1.0 (1.275 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 403 into models/all_cnn2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 43.7976\n",
      "INFO:tensorflow:loss = 0.128508, step = 403 (2.284 sec)\n",
      "INFO:tensorflow:loss = 0.128508, accuracy = 0.953125 (1.009 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 453 into models/all_cnn2/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0606024, accuracy = 1.0 (1.011 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 503 into models/all_cnn2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.6178\n",
      "INFO:tensorflow:loss = 0.126456, step = 503 (17.801 sec)\n",
      "INFO:tensorflow:loss = 0.126456, accuracy = 0.984375 (16.789 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7f3795772842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m estimator.train(\n\u001b[0;32m----> 4\u001b[0;31m     input_fn = lambda: input_fn(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    893\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "estimator.train(\n",
    "    input_fn = lambda: input_fn(\n",
    "        dataset.training_set.df, \n",
    "        batch_size = params.batch_size, \n",
    "        epochs = params.epochs,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "## AllCNN\n",
      "##########################\n",
      "Tensor(\"IteratorGetNext:0\", shape=(64, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm/Elu:0\", shape=(64, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm_1/Elu:0\", shape=(64, 7, 7, 32), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm_2/Elu:0\", shape=(64, 5, 5, 64), dtype=float32)\n",
      "Tensor(\"AllCNN/conv2d/Elu:0\", shape=(64, 3, 3, 10), dtype=float32)\n",
      "Tensor(\"AllCNN/conv2d/Elu:0\", shape=(64, 3, 3, 10), dtype=float32)\n",
      "\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-19-21:06:45\n",
      "INFO:tensorflow:Restoring parameters from models/all_cnn1/model.ckpt-5601\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-19-21:10:25\n",
      "INFO:tensorflow:Saving dict for global step 5601: accuracy = 0.990324, global_step = 5601, loss = 0.0323472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.99032396, 'global_step': 5601, 'loss': 0.032347161}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "estimator.evaluate(\n",
    "    input_fn = lambda: input_fn(\n",
    "        dataset.test_set.df, \n",
    "        batch_size = params.batch_size, \n",
    "        epochs = 1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "iterator = estimator.predict(\n",
    "    input_fn = lambda: input_fn(\n",
    "        dataset.test_set.df, \n",
    "        batch_size = 64, \n",
    "        epochs = 1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "##########################\n",
      "## AllCNN\n",
      "##########################\n",
      "Tensor(\"IteratorGetNext:0\", shape=(64, 28, 28, 1), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm/Elu:0\", shape=(64, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm_1/Elu:0\", shape=(64, 7, 7, 32), dtype=float32)\n",
      "Tensor(\"AllCNN/Conv2dBatchNorm_2/Elu:0\", shape=(64, 5, 5, 64), dtype=float32)\n",
      "Tensor(\"AllCNN/conv2d/Elu:0\", shape=(64, 3, 3, 10), dtype=float32)\n",
      "Tensor(\"AllCNN/Mean:0\", shape=(64, 10), dtype=float32)\n",
      "Tensor(\"AllCNN/Softmax:0\", shape=(64, 10), dtype=float32)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from models/all_cnn1/model.ckpt-5601\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD7CAYAAABt9agKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQMKFQMKFQP8GBaTgkI7SQ1IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f02b1984250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = next(iterator)\n",
    "\n",
    "img = predictions[\"image\"]\n",
    "class_id = np.argmax(predictions[\"classes\"])\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "plt.imshow(img[:, :, 0], cmap=\"gray\")\n",
    "\n",
    "ax.title.set_text(class_id)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    inputs = dict(\n",
    "        image = tf.layers.Input(shape=(28, 28, 1)),\n",
    "        mode = tf.estimator.ModeKeys.TRAIN,\n",
    "    )\n",
    "\n",
    "    all_cnn = AllCNNN()\n",
    "    logits, predictions = all_cnn(inputs)\n",
    "    \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "sess_config = tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=graph, config=sess_config)\n",
    "snapshot_fpath = tf.train.latest_checkpoint(params.model_dir)\n",
    "saver.restore(sess, snapshot_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 14 variables.\n",
      "Converted 14 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./frozen_models/all_cnn1.pb'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
    "\n",
    "graphdef_frozen = tf.graph_util.convert_variables_to_constants(\n",
    "    sess, graphdef_inf, params.OUTPUT_NAMES)\n",
    "\n",
    "graph_io.write_graph(graphdef_frozen, './', params.FROZEN_FPATH, as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'input_layer_1',\n",
       " u'AllCNN/Conv2dBatchNorm/conv2d/kernel',\n",
       " u'AllCNN/Conv2dBatchNorm/conv2d/bias',\n",
       " u'AllCNN/Conv2dBatchNorm/conv2d/Conv2D',\n",
       " u'AllCNN/Conv2dBatchNorm/conv2d/BiasAdd',\n",
       " u'AllCNN/Conv2dBatchNorm/batch_normalization/gamma',\n",
       " u'AllCNN/Conv2dBatchNorm/batch_normalization/beta',\n",
       " u'AllCNN/Conv2dBatchNorm/batch_normalization/Const',\n",
       " u'AllCNN/Conv2dBatchNorm/batch_normalization/Const_1',\n",
       " u'AllCNN/Conv2dBatchNorm/batch_normalization/FusedBatchNorm',\n",
       " u'AllCNN/Conv2dBatchNorm/Elu',\n",
       " u'AllCNN/Conv2dBatchNorm_1/conv2d/kernel',\n",
       " u'AllCNN/Conv2dBatchNorm_1/conv2d/bias',\n",
       " u'AllCNN/Conv2dBatchNorm_1/conv2d/Conv2D',\n",
       " u'AllCNN/Conv2dBatchNorm_1/conv2d/BiasAdd',\n",
       " u'AllCNN/Conv2dBatchNorm_1/batch_normalization/gamma',\n",
       " u'AllCNN/Conv2dBatchNorm_1/batch_normalization/beta',\n",
       " u'AllCNN/Conv2dBatchNorm_1/batch_normalization/Const',\n",
       " u'AllCNN/Conv2dBatchNorm_1/batch_normalization/Const_1',\n",
       " u'AllCNN/Conv2dBatchNorm_1/batch_normalization/FusedBatchNorm',\n",
       " u'AllCNN/Conv2dBatchNorm_1/Elu',\n",
       " u'AllCNN/Conv2dBatchNorm_2/conv2d/kernel',\n",
       " u'AllCNN/Conv2dBatchNorm_2/conv2d/bias',\n",
       " u'AllCNN/Conv2dBatchNorm_2/conv2d/Conv2D',\n",
       " u'AllCNN/Conv2dBatchNorm_2/conv2d/BiasAdd',\n",
       " u'AllCNN/Conv2dBatchNorm_2/batch_normalization/gamma',\n",
       " u'AllCNN/Conv2dBatchNorm_2/batch_normalization/beta',\n",
       " u'AllCNN/Conv2dBatchNorm_2/batch_normalization/Const',\n",
       " u'AllCNN/Conv2dBatchNorm_2/batch_normalization/Const_1',\n",
       " u'AllCNN/Conv2dBatchNorm_2/batch_normalization/FusedBatchNorm',\n",
       " u'AllCNN/Conv2dBatchNorm_2/Elu',\n",
       " u'AllCNN/conv2d/kernel',\n",
       " u'AllCNN/conv2d/bias',\n",
       " u'AllCNN/conv2d/Conv2D',\n",
       " u'AllCNN/conv2d/BiasAdd',\n",
       " u'AllCNN/conv2d/Elu',\n",
       " u'AllCNN/Mean/reduction_indices',\n",
       " u'AllCNN/Mean',\n",
       " u'AllCNN/Softmax']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.name for x in graphdef_frozen.node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import uff\n",
    "from tensorrt.parsers import uffparser\n",
    "\n",
    "MAX_WORKSPACE = 1 << 20 # ADJUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using output node AllCNN/Softmax\n",
      "Converting to UFF graph\n",
      "Warning: No conversion function registered for layer: Elu yet.\n",
      "Converting as custom op Elu AllCNN/conv2d/Elu\n",
      "name: \"AllCNN/conv2d/Elu\"\n",
      "op: \"Elu\"\n",
      "input: \"AllCNN/conv2d/BiasAdd\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n",
      "Warning: No conversion function registered for layer: Elu yet.\n",
      "Converting as custom op Elu AllCNN/Conv2dBatchNorm_2/Elu\n",
      "name: \"AllCNN/Conv2dBatchNorm_2/Elu\"\n",
      "op: \"Elu\"\n",
      "input: \"AllCNN/Conv2dBatchNorm_2/batch_normalization/FusedBatchNorm\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n",
      "Warning: No conversion function registered for layer: Elu yet.\n",
      "Converting as custom op Elu AllCNN/Conv2dBatchNorm_1/Elu\n",
      "name: \"AllCNN/Conv2dBatchNorm_1/Elu\"\n",
      "op: \"Elu\"\n",
      "input: \"AllCNN/Conv2dBatchNorm_1/batch_normalization/FusedBatchNorm\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n",
      "Warning: No conversion function registered for layer: Elu yet.\n",
      "Converting as custom op Elu AllCNN/Conv2dBatchNorm/Elu\n",
      "name: \"AllCNN/Conv2dBatchNorm/Elu\"\n",
      "op: \"Elu\"\n",
      "input: \"AllCNN/Conv2dBatchNorm/batch_normalization/FusedBatchNorm\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n",
      "No. nodes: 39\n"
     ]
    }
   ],
   "source": [
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "uff_model = uff.from_tensorflow_frozen_model(\n",
    "    params.FROZEN_FPATH, \n",
    "    params.OUTPUT_NAMES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "parser = uffparser.create_uff_parser()\n",
    "\n",
    "for input_ in params.INPUTS:\n",
    "    parser.register_input(input_.name, input_.size, 0)\n",
    "\n",
    "for output in params.OUTPUT_NAMES:\n",
    "    parser.register_output(output)\n",
    "\n",
    "G_LOGGER = trt.infer.ConsoleLogger(trt.infer.LogSeverity.INTERNAL_ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed to create session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4e93b15435db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m     \"\"\"\n\u001b[0;32m-> 1482\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    620\u001b[0m           \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewDeprecatedSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteSessionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristian/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to create session."
     ]
    }
   ],
   "source": [
    "params = dicto.load_(\"parameters.yml\")\n",
    "\n",
    "graph = tf.Graph()\n",
    "sess = tf.Session(graph = graph)\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    inputs = dict(\n",
    "        image = tf.layers.Input(shape=(28, 28, 1)),\n",
    "        mode = tf.estimator.ModeKeys.TRAIN,\n",
    "    )\n",
    "\n",
    "    all_cnn = AllCNNN()\n",
    "    logits, predictions = all_cnn(inputs)\n",
    "    \n",
    "    graph_def = graph.as_graph_def()\n",
    "    \n",
    "    print(predictions.graph)\n",
    "    print(graph)\n",
    "    print(sess.graph)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    snapshot_fpath = tf.train.latest_checkpoint(params.model_dir)\n",
    "    saver.restore(sess, snapshot_fpath)\n",
    "    \n",
    "    # freeze graph and remove nodes used for training \n",
    "    frozen_graph = tf.graph_util.convert_variables_to_constants(sess, graph_def, params.OUTPUT_NAMES)\n",
    "    frozen_graph = tf.graph_util.remove_training_nodes(frozen_graph)\n",
    "    # Create UFF model and dump it on disk \n",
    "    uff_model = uff.from_tensorflow(frozen_graph, [predictions.name])\n",
    "    dump = open('all_cnn.uff', 'wb')\n",
    "    dump.write(uff_model)\n",
    "    dump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'AllCNN/Softmax:0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
